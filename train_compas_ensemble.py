import os
import pandas as pd
import numpy as np
import datetime
import logging

from sklearn.metrics import classification_report

from autogluon.tabular import  TabularPredictor
from autogluon.fair import FairPredictor
from autogluon.fair.utils import group_metrics as gm

from create_dataset_compas import split_dataset, undersample_by_column, join_tabular_compas_for_risk

logging.basicConfig(level=logging.INFO)


def run_default_training(model_outpath=None, use_race=False):
    """
    Run default training used in our example 
    
    Attributes
    ----------
    model_outpath : str 
        if none it will be uniquely autogenerated to avoid overwriting 
    use_race: bool
        whether to use the race column in training
    """ 
    ####### Project parameters 

    # task we're solving
    # eg. pred_label is felony in the next n years
    current_label = 'pred_label' 

    # how many years do we want our prediction label to encompass
    # i.e. years=1 means the suspect is likely to commit a felony 
    # in the next 1 year
    years = 1

    #datapath 
    basepath = f'joined_data/compas_v2_all_{years}y-label'
    inpath = basepath + '.pqt'
    compas_db = 'compas.db'
    # do we want to undersample
    undersampling = False 

    # do we want to train a new model or just run fairness modification
    # on an existing model
    rstr = 'norace'
    if use_race:
        rstr = 'race'

    outpath = model_outpath
    if not model_outpath:
        now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        outpath = f'AutogluonModels/ag-{now}-v2-{years}y-{current_label[:-6]}-{rstr}'
    
    try:
        train, test, val = load_data(basepath)
    except:
        # if joined up data doesn't exist generate it from the compas database
        generate_data(compas_db, outpath=inpath, prediction_years=years)
        train, test, val = load_data(basepath)


    # in case we added other labels to the dataset e.g. future murder label
    all_pred_labels = []
    for c in train.columns:
        if '_label' in c:
            all_pred_labels.append(c)

    # person id not needed after splitting 
    # leaving in could prejudice the performance 
    drop_cols =  list(set(all_pred_labels+['person_id'])-set([current_label] ))
    logging.info(f'Dropping columns: {drop_cols}')
    train = train.drop(columns=drop_cols)
    test = test.drop(columns=drop_cols)
    val = val.drop(columns=drop_cols)

    predictor = train_ensamble(train, val, outpath=outpath, use_race=use_race, current_label='pred_label', undersampling=undersampling)
    test_predictor(predictor, test)
    return predictor 

def generate_data(compas_db='compas.db', outpath=None, prediction_years=1):
    """
    Generate a joined up dataset from the original database 
    
    Attributes
    ----------
    compas_db : str
        path to the compas database 
    outpath : str
        location for the parquet file of the joined up data 
    prediction_years : int
        lookahead years for creation of the prediction label 
    """ 
    if not os.path.exists(compas_db):
        logging.error(f'No such file: {compas_db}')
        raise ImportError
    logging.info('\n*****Generating joined compas data******\n')
    data = join_tabular_compas_for_risk(compas_db, years=prediction_years)
    if outpath:
        data.to_parquet(outpath)
    return data


def load_data(basepath):
    """
    Load the data and separate in to train, test, validation parts if 
    the splits haven't been saved already. 
        
    Attributes
    ----------
    basepath : str
        base name of the data file without the extension or the splt inidcators 
        e.g. _train.pqt 
    """    
    
    if basepath.endswith('.pqt'):
        inpath = basepath
        basepath = basepath[:-4]
    else:
        inpath = basepath + '.pqt'

    datasets = {'train':None, 'test':None, 'val':None}
    all_data = pd.DataFrame([])
    for d in datasets.keys():
        if os.path.exists(f'{basepath}_{d}.pqt'):
            datasets[d] = pd.read_parquet(f'{basepath}_{d}.pqt')
        else:
            if not os.path.exists(inpath):
                logging.error(f'No such file: {inpath}')
                raise ImportError
    
            else:
                
                all_data = pd.read_parquet(inpath)
            break

    if all_data.empty:
        train = datasets['train']
        test = datasets['test']
        val = datasets['val']
    else:
        train, test, val = split_dataset(all_data)
        save_name = inpath[:-4] + '_train.pqt'
        train.to_parquet(path=save_name)
        save_name = inpath[:-4] + '_test.pqt'
        test.to_parquet(path=save_name)
        save_name = inpath[:-4] + '_val.pqt'
        val.to_parquet(path= save_name)
   
    return train, test, val


def train_ensamble(train, val, outpath=None, use_race=False, current_label='pred_label', undersampling=False):
    """ 
    Train an autogluon model
    
    Attributes
    ----------
    train : pandas dataframe
    val : pandas dataframe    
    outpath : str
        location where to save the model  
    use_race : bool
        whether to drop the race column during the training 
    current_label :  str
        column name of the prediction label 
    undersampling : bool
        whether to undersample the data to even out the numbers of 
        African American and Caucasian data points
    """ 

    if undersampling:
        train = undersample_by_column(train, 'race','african-american', 'caucasian')

 
    drop_r_cols = ['race']
    if use_race: 
        drop_r_cols = []

    predictor = TabularPredictor(label=current_label, 
                                eval_metric='f1_macro',
                                path=outpath).fit(train.drop(columns=drop_r_cols), 
                                                tuning_data = val.drop(columns=drop_r_cols),  
                                                keep_only_best=True,  
                                                excluded_model_types=['GBM'],# excluding as not working on OSX
                                                num_gpus=0)#, presets="medium_quality") # uncomment for a faster run

    return predictor


def train_fair(predictor, train, column='race'):
    """ 
    Train an autogluon fair model
    
    Attributes
    ----------
    predictor : autogluon model
    train : pandas dataframe    
    column : str
        column name for the mode used for fairness calculation e.g race or gender
    """ 

    # Modify predictor to enforce fairness over the train_data with respect to groups given by the column 'race'
    fpredictor = FairPredictor(predictor,train,column)
    
    # Maximize accuracy while enforcing that the demographic parity (the difference in positive decision rates between different race values is at most 0.02)
    fpredictor.fit(gm.f1,gm.demographic_parity,0.02)
    return fpredictor


def test_predictor(predictor, test, prediction_label = 'pred_label'):
   
    # predict the values on the test set
    y_pred = predictor.predict(test.drop(columns = [prediction_label]))
    logging.info(predictor.leaderboard(test, silent=True))
    y_test = test[prediction_label]

    logging.info(classification_report(y_test, y_pred))
    return y_pred

def test_fair_predictor(fpredictor, test, prediction_label = 'pred_label'):
    
    y_test = test[prediction_label]

    # Evaluate on test data
    y_pred = fpredictor.predict(test.drop(columns=[prediction_label]))

    logging.info(classification_report(y_test, y_pred))

    # Evaluate a range of performance measures, and compare against original classifier on test data
    logging.info(fpredictor.evaluate(test, verbose=True))

    logging.info(fpredictor.evaluate_groups(test, verbose=True, return_original=True))

    # Evaluate against a range of standard fairness definitions and compare against original classifier on test data
    logging.info(fpredictor.evaluate_fairness(test, verbose=True))

    logging.info(fpredictor.evaluate_fairness(test, metrics=gm.clarify_metrics, verbose=True))
    return y_pred
